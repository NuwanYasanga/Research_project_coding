{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b11c58d",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9451c366",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import scipy\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential \n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "import tensorflow.keras.layers as tfl\n",
    "from tensorflow.python.framework import ops\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581cd456",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77502522",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_merged = pd.read_csv('C:/Users/s3929438/all_features_desktop_100_final_latest.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cf65c7",
   "metadata": {},
   "source": [
    "# Select a single user\n",
    "## Create the training and testing sets for the user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d47a5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_train_set = all_merged[all_merged['User']==1].sample(frac=0.7, random_state=42)\n",
    "sample_ids = user_train_set['sample']\n",
    "user_test_set = all_merged[(all_merged['User']==1) & ~all_merged['sample'].isin (sample_ids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43394f1c",
   "metadata": {},
   "source": [
    "## Create the training and testing sets for all other users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b9a5b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_set  = pd.DataFrame()\n",
    "all_test_set = pd.DataFrame()\n",
    "user_id = 1\n",
    "for i in range (1,117):\n",
    "    if i != user_id:\n",
    "        train_set = all_merged[all_merged['User']==i].sample(frac=0.7, random_state=42)\n",
    "        sample_ids = train_set['sample']\n",
    "        test_set = all_merged[(all_merged['User']==i) & ~all_merged['sample'].isin (sample_ids) ]\n",
    "    \n",
    "        all_train_set = all_train_set.append(train_set,ignore_index=True)\n",
    "        all_test_set = all_test_set.append(test_set, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3be168d",
   "metadata": {},
   "source": [
    "# Add a new column by labelling the User data as 1 and all others data as 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c064621c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s3929438\\AppData\\Local\\Temp/ipykernel_18812/4033866476.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  user_test_set['User_type']=1\n"
     ]
    }
   ],
   "source": [
    "user_train_set['User_type']=1\n",
    "all_train_set['User_type']=0\n",
    "user_test_set['User_type']=1\n",
    "all_test_set['User_type']=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cba9b2",
   "metadata": {},
   "source": [
    "# Combine all users and build the final datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c46d207b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train_set = user_train_set.append(all_train_set)\n",
    "final_test_set = user_test_set.append(all_test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fcb4f9",
   "metadata": {},
   "source": [
    "# Define the x_train, x_test, y_train and y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1038ae2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(final_train_set.iloc[:,3:92])\n",
    "y_train =final_train_set.iloc[:,92]\n",
    "X_test = pd.DataFrame(final_test_set.iloc[:,3:92])\n",
    "y_test = final_test_set.iloc[:,92]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3d8669d",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ebdcbf",
   "metadata": {},
   "source": [
    "# Oversample the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12ce750d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE()\n",
    "x_train_res, y_train_res = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb765e1",
   "metadata": {},
   "source": [
    "# Normalised x_train and x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b2ec855",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data = MinMaxScaler()\n",
    "scaled_train = pd.DataFrame(scaled_data.fit_transform(x_train_res), columns=feature_names)\n",
    "scaled_test = pd.DataFrame(scaled_data.transform(X_test), columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402610b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def KeystrokeModel():\n",
    "\n",
    "#     model = tf.keras.Sequential([\n",
    "           \n",
    "#             tfl.ZeroPadding2D(padding=(0,0) , input_shape = (8850, 89,1), data_format=\"channels_last\"),\n",
    "#             tfl.Conv2D(32, (100,89), strides = (90,1)),\n",
    "#             tfl.BatchNormalization(axis= 3),\n",
    "#             tfl.ReLU(max_value=None, negative_slope=0.0, threshold=0.0),\n",
    "# #             tfl.MaxPool2D(pool_size=(5, 89),strides=None,data_format=None),\n",
    "# #             tfl.Conv2D(16, (5,5), strides = (4,4)),\n",
    "# #             tfl.BatchNormalization(axis= 3),\n",
    "# #             tfl.ReLU(max_value=None, negative_slope=0.0, threshold=0.0),\n",
    "# #             tfl.MaxPool2D(pool_size=(2, 2),strides=None,data_format=None),\n",
    "#             tfl.Flatten(),\n",
    "#             tfl.Dense(3136,activation='relu'),\n",
    "#             tfl.Dense(1,activation='sigmoid')\n",
    "#         ])\n",
    "    \n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f148fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = KeystrokeModel()\n",
    "# model.compile(optimizer='adam',\n",
    "#                    loss='binary_crossentropy',\n",
    "#                    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c693d93f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90a9030",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9559b6e",
   "metadata": {},
   "source": [
    "# Apply general deep learning model\n",
    "\n",
    "### This model working fine. But the results we achived are very low. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7739b0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperated the training set into training and validation set\n",
    "x_train, x_val ,  y_train, y_val = train_test_split(scaled_train, y_train_res, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dade744a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3103\n",
       "1    3092\n",
       "Name: User_type, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc37d288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error_rate_%</th>\n",
       "      <th>Cpslck_usage</th>\n",
       "      <th>WPM</th>\n",
       "      <th>neg_UD_%</th>\n",
       "      <th>neg_UU_%</th>\n",
       "      <th>mean_hold_time</th>\n",
       "      <th>mean_F1_dis_0_LL</th>\n",
       "      <th>mean_F1_dis_0_RR</th>\n",
       "      <th>mean_F1_dis_1_LL</th>\n",
       "      <th>mean_F1_dis_1_RR</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_F1_co</th>\n",
       "      <th>mean_F2_co</th>\n",
       "      <th>mean_F3_co</th>\n",
       "      <th>mean_F4_co</th>\n",
       "      <th>mean_F1_le</th>\n",
       "      <th>mean_F2_le</th>\n",
       "      <th>mean_F3_le</th>\n",
       "      <th>mean_F4_le</th>\n",
       "      <th>RSA_ratio</th>\n",
       "      <th>LSA_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3207</th>\n",
       "      <td>0.209302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.288801</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015665</td>\n",
       "      <td>0.019643</td>\n",
       "      <td>0.218896</td>\n",
       "      <td>0.144789</td>\n",
       "      <td>...</td>\n",
       "      <td>0.319134</td>\n",
       "      <td>0.112932</td>\n",
       "      <td>0.065482</td>\n",
       "      <td>0.085268</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.126855</td>\n",
       "      <td>0.075256</td>\n",
       "      <td>0.090120</td>\n",
       "      <td>0.804545</td>\n",
       "      <td>0.804545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3001</th>\n",
       "      <td>0.139535</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.056833</td>\n",
       "      <td>0.193127</td>\n",
       "      <td>0.126276</td>\n",
       "      <td>0.098585</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.182682</td>\n",
       "      <td>0.151010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.291445</td>\n",
       "      <td>0.050930</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.232275</td>\n",
       "      <td>0.074677</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2118</th>\n",
       "      <td>0.255814</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.204393</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027432</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.134663</td>\n",
       "      <td>0.134543</td>\n",
       "      <td>...</td>\n",
       "      <td>0.291445</td>\n",
       "      <td>0.050930</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.232275</td>\n",
       "      <td>0.074677</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6165</th>\n",
       "      <td>0.104420</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.054450</td>\n",
       "      <td>0.118657</td>\n",
       "      <td>0.075572</td>\n",
       "      <td>0.106447</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046530</td>\n",
       "      <td>0.230293</td>\n",
       "      <td>0.166939</td>\n",
       "      <td>...</td>\n",
       "      <td>0.343385</td>\n",
       "      <td>0.151949</td>\n",
       "      <td>0.126985</td>\n",
       "      <td>0.149127</td>\n",
       "      <td>0.339725</td>\n",
       "      <td>0.219908</td>\n",
       "      <td>0.179903</td>\n",
       "      <td>0.192350</td>\n",
       "      <td>0.813740</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6871</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.302155</td>\n",
       "      <td>0.129264</td>\n",
       "      <td>0.036964</td>\n",
       "      <td>0.059344</td>\n",
       "      <td>0.023797</td>\n",
       "      <td>0.035305</td>\n",
       "      <td>0.182265</td>\n",
       "      <td>0.184514</td>\n",
       "      <td>...</td>\n",
       "      <td>0.291445</td>\n",
       "      <td>0.050930</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.232275</td>\n",
       "      <td>0.074677</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.887147</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5734</th>\n",
       "      <td>0.104596</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.335049</td>\n",
       "      <td>0.095600</td>\n",
       "      <td>0.010433</td>\n",
       "      <td>0.044844</td>\n",
       "      <td>0.018057</td>\n",
       "      <td>0.034059</td>\n",
       "      <td>0.188056</td>\n",
       "      <td>0.218914</td>\n",
       "      <td>...</td>\n",
       "      <td>0.291445</td>\n",
       "      <td>0.050930</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.232275</td>\n",
       "      <td>0.074677</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250395</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>0.025176</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.413989</td>\n",
       "      <td>0.212628</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063173</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.185196</td>\n",
       "      <td>0.150440</td>\n",
       "      <td>...</td>\n",
       "      <td>0.291445</td>\n",
       "      <td>0.050930</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.232275</td>\n",
       "      <td>0.074677</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.180430</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>0.139535</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.309888</td>\n",
       "      <td>0.016948</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040007</td>\n",
       "      <td>0.019296</td>\n",
       "      <td>0.040379</td>\n",
       "      <td>0.194201</td>\n",
       "      <td>0.159072</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261467</td>\n",
       "      <td>0.109803</td>\n",
       "      <td>0.063247</td>\n",
       "      <td>0.148841</td>\n",
       "      <td>0.265160</td>\n",
       "      <td>0.135682</td>\n",
       "      <td>0.100196</td>\n",
       "      <td>0.111669</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.212778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.217279</td>\n",
       "      <td>0.153490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.346823</td>\n",
       "      <td>0.140390</td>\n",
       "      <td>0.102432</td>\n",
       "      <td>0.111862</td>\n",
       "      <td>0.265079</td>\n",
       "      <td>0.126855</td>\n",
       "      <td>0.093919</td>\n",
       "      <td>0.097831</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>0.103238</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.269761</td>\n",
       "      <td>0.119089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059372</td>\n",
       "      <td>0.007871</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.188317</td>\n",
       "      <td>0.157063</td>\n",
       "      <td>...</td>\n",
       "      <td>0.291445</td>\n",
       "      <td>0.050930</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.232275</td>\n",
       "      <td>0.074677</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.609805</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6195 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Error_rate_%  Cpslck_usage       WPM  neg_UD_%  neg_UU_%  \\\n",
       "3207      0.209302           0.0  0.288801  0.029412  0.000000   \n",
       "3001      0.139535           0.0  0.056833  0.193127  0.126276   \n",
       "2118      0.255814           0.0  0.204393  0.029412  0.000000   \n",
       "6165      0.104420           0.0  0.054450  0.118657  0.075572   \n",
       "6871      0.000000           0.0  0.302155  0.129264  0.036964   \n",
       "...            ...           ...       ...       ...       ...   \n",
       "5734      0.104596           0.0  0.335049  0.095600  0.010433   \n",
       "5191      0.025176           0.0  0.413989  0.212628  0.000000   \n",
       "5390      0.139535           0.0  0.309888  0.016948  0.000000   \n",
       "860       0.046512           0.0  0.212778  0.000000  0.000000   \n",
       "7270      0.103238           0.0  0.269761  0.119089  0.000000   \n",
       "\n",
       "      mean_hold_time  mean_F1_dis_0_LL  mean_F1_dis_0_RR  mean_F1_dis_1_LL  \\\n",
       "3207        0.000000          0.015665          0.019643          0.218896   \n",
       "3001        0.098585          0.000000          0.000000          0.182682   \n",
       "2118        0.027432          0.000000          0.000000          0.134663   \n",
       "6165        0.106447          0.000000          0.046530          0.230293   \n",
       "6871        0.059344          0.023797          0.035305          0.182265   \n",
       "...              ...               ...               ...               ...   \n",
       "5734        0.044844          0.018057          0.034059          0.188056   \n",
       "5191        0.063173          0.000000          0.000000          0.185196   \n",
       "5390        0.040007          0.019296          0.040379          0.194201   \n",
       "860         0.023048          0.000000          0.000000          0.217279   \n",
       "7270        0.059372          0.007871          0.000000          0.188317   \n",
       "\n",
       "      mean_F1_dis_1_RR  ...  mean_F1_co  mean_F2_co  mean_F3_co  mean_F4_co  \\\n",
       "3207          0.144789  ...    0.319134    0.112932    0.065482    0.085268   \n",
       "3001          0.151010  ...    0.291445    0.050930    0.000000    0.000000   \n",
       "2118          0.134543  ...    0.291445    0.050930    0.000000    0.000000   \n",
       "6165          0.166939  ...    0.343385    0.151949    0.126985    0.149127   \n",
       "6871          0.184514  ...    0.291445    0.050930    0.000000    0.000000   \n",
       "...                ...  ...         ...         ...         ...         ...   \n",
       "5734          0.218914  ...    0.291445    0.050930    0.000000    0.000000   \n",
       "5191          0.150440  ...    0.291445    0.050930    0.000000    0.000000   \n",
       "5390          0.159072  ...    0.261467    0.109803    0.063247    0.148841   \n",
       "860           0.153490  ...    0.346823    0.140390    0.102432    0.111862   \n",
       "7270          0.157063  ...    0.291445    0.050930    0.000000    0.000000   \n",
       "\n",
       "      mean_F1_le  mean_F2_le  mean_F3_le  mean_F4_le  RSA_ratio  LSA_ratio  \n",
       "3207    0.257143    0.126855    0.075256    0.090120   0.804545   0.804545  \n",
       "3001    0.232275    0.074677    0.000000    0.000000   0.187500   0.812500  \n",
       "2118    0.232275    0.074677    0.000000    0.000000   1.000000   1.000000  \n",
       "6165    0.339725    0.219908    0.179903    0.192350   0.813740   0.000000  \n",
       "6871    0.232275    0.074677    0.000000    0.000000   0.887147   0.000000  \n",
       "...          ...         ...         ...         ...        ...        ...  \n",
       "5734    0.232275    0.074677    0.000000    0.000000   0.250395   0.000000  \n",
       "5191    0.232275    0.074677    0.000000    0.000000   0.180430   0.000000  \n",
       "5390    0.265160    0.135682    0.100196    0.111669   0.000000   0.000000  \n",
       "860     0.265079    0.126855    0.093919    0.097831   1.000000   1.000000  \n",
       "7270    0.232275    0.074677    0.000000    0.000000   0.609805   0.000000  \n",
       "\n",
       "[6195 rows x 89 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37d96b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x_train.values\n",
    "Y = y_train.values\n",
    "val_x = x_val.values\n",
    "val_y = y_val.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df4571ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 264)               23760     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 265       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,025\n",
      "Trainable params: 24,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(tfl.Dense(264, input_dim=89, activation='relu')) \n",
    "# model.add(tfl.Dense(128, activation='relu'))\n",
    "model.add(tfl.Dense(1, activation='sigmoid'))\n",
    "model.summary() \n",
    "model.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy', Precision() ,Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3ce5784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping \n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09630297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "165/194 [========================>.....] - ETA: 0s - loss: 0.3544 - accuracy: 0.9072 - precision: 0.8594 - recall: 0.9739      \n",
      "Epoch 1: val_accuracy improved from -inf to 0.95028, saving model to best_model.h5\n",
      "194/194 [==============================] - 1s 4ms/step - loss: 0.3302 - accuracy: 0.9127 - precision: 0.8649 - recall: 0.9777 - val_loss: 0.1985 - val_accuracy: 0.9503 - val_precision: 0.9116 - val_recall: 0.9977\n",
      "Epoch 2/100\n",
      "174/194 [=========================>....] - ETA: 0s - loss: 0.1581 - accuracy: 0.9499 - precision: 0.9093 - recall: 0.9993\n",
      "Epoch 2: val_accuracy improved from 0.95028 to 0.95480, saving model to best_model.h5\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 0.1556 - accuracy: 0.9504 - precision: 0.9102 - recall: 0.9994 - val_loss: 0.1462 - val_accuracy: 0.9548 - val_precision: 0.9174 - val_recall: 1.0000\n",
      "Epoch 3/100\n",
      "161/194 [=======================>......] - ETA: 0s - loss: 0.1295 - accuracy: 0.9596 - precision: 0.9253 - recall: 1.0000\n",
      "Epoch 3: val_accuracy improved from 0.95480 to 0.96045, saving model to best_model.h5\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 0.1260 - accuracy: 0.9616 - precision: 0.9285 - recall: 1.0000 - val_loss: 0.1287 - val_accuracy: 0.9605 - val_precision: 0.9270 - val_recall: 1.0000\n",
      "Epoch 4/100\n",
      "183/194 [===========================>..] - ETA: 0s - loss: 0.1076 - accuracy: 0.9657 - precision: 0.9354 - recall: 1.0000\n",
      "Epoch 4: val_accuracy improved from 0.96045 to 0.96347, saving model to best_model.h5\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 0.1059 - accuracy: 0.9666 - precision: 0.9373 - recall: 1.0000 - val_loss: 0.1156 - val_accuracy: 0.9635 - val_precision: 0.9322 - val_recall: 1.0000\n",
      "Epoch 5/100\n",
      "178/194 [==========================>...] - ETA: 0s - loss: 0.0954 - accuracy: 0.9702 - precision: 0.9439 - recall: 0.9993\n",
      "Epoch 5: val_accuracy improved from 0.96347 to 0.96610, saving model to best_model.h5\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 0.0932 - accuracy: 0.9708 - precision: 0.9452 - recall: 0.9994 - val_loss: 0.1094 - val_accuracy: 0.9661 - val_precision: 0.9368 - val_recall: 1.0000\n",
      "Epoch 6/100\n",
      "165/194 [========================>.....] - ETA: 0s - loss: 0.0814 - accuracy: 0.9754 - precision: 0.9531 - recall: 1.0000\n",
      "Epoch 6: val_accuracy improved from 0.96610 to 0.97363, saving model to best_model.h5\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 0.0832 - accuracy: 0.9748 - precision: 0.9520 - recall: 1.0000 - val_loss: 0.0985 - val_accuracy: 0.9736 - val_precision: 0.9501 - val_recall: 1.0000\n",
      "Epoch 7/100\n",
      "172/194 [=========================>....] - ETA: 0s - loss: 0.0728 - accuracy: 0.9778 - precision: 0.9577 - recall: 1.0000\n",
      "Epoch 7: val_accuracy did not improve from 0.97363\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 0.0741 - accuracy: 0.9771 - precision: 0.9561 - recall: 1.0000 - val_loss: 0.0902 - val_accuracy: 0.9718 - val_precision: 0.9467 - val_recall: 1.0000\n",
      "Epoch 8/100\n",
      "179/194 [==========================>...] - ETA: 0s - loss: 0.0658 - accuracy: 0.9787 - precision: 0.9592 - recall: 1.0000\n",
      "Epoch 8: val_accuracy improved from 0.97363 to 0.97589, saving model to best_model.h5\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 0.0661 - accuracy: 0.9785 - precision: 0.9588 - recall: 1.0000 - val_loss: 0.0821 - val_accuracy: 0.9759 - val_precision: 0.9542 - val_recall: 1.0000\n",
      "Epoch 9/100\n",
      "181/194 [==========================>...] - ETA: 0s - loss: 0.0594 - accuracy: 0.9801 - precision: 0.9618 - recall: 1.0000\n",
      "Epoch 9: val_accuracy improved from 0.97589 to 0.98041, saving model to best_model.h5\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 0.0603 - accuracy: 0.9800 - precision: 0.9614 - recall: 1.0000 - val_loss: 0.0813 - val_accuracy: 0.9804 - val_precision: 0.9625 - val_recall: 1.0000\n",
      "Epoch 10/100\n",
      "182/194 [===========================>..] - ETA: 0s - loss: 0.0552 - accuracy: 0.9839 - precision: 0.9686 - recall: 1.0000\n",
      "Epoch 10: val_accuracy did not improve from 0.98041\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 0.0550 - accuracy: 0.9840 - precision: 0.9690 - recall: 1.0000 - val_loss: 0.0712 - val_accuracy: 0.9770 - val_precision: 0.9562 - val_recall: 1.0000\n",
      "Epoch 11/100\n",
      "162/194 [========================>.....] - ETA: 0s - loss: 0.0496 - accuracy: 0.9846 - precision: 0.9700 - recall: 1.0000\n",
      "Epoch 11: val_accuracy did not improve from 0.98041\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 0.0479 - accuracy: 0.9853 - precision: 0.9714 - recall: 1.0000 - val_loss: 0.0728 - val_accuracy: 0.9751 - val_precision: 0.9528 - val_recall: 1.0000\n",
      "Epoch 12/100\n",
      "162/194 [========================>.....] - ETA: 0s - loss: 0.0447 - accuracy: 0.9859 - precision: 0.9727 - recall: 1.0000\n",
      "Epoch 12: val_accuracy improved from 0.98041 to 0.98117, saving model to best_model.h5\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 0.0428 - accuracy: 0.9864 - precision: 0.9736 - recall: 1.0000 - val_loss: 0.0607 - val_accuracy: 0.9812 - val_precision: 0.9638 - val_recall: 1.0000\n",
      "Epoch 13/100\n",
      "170/194 [=========================>....] - ETA: 0s - loss: 0.0401 - accuracy: 0.9881 - precision: 0.9766 - recall: 1.0000\n",
      "Epoch 13: val_accuracy did not improve from 0.98117\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 0.0394 - accuracy: 0.9885 - precision: 0.9776 - recall: 1.0000 - val_loss: 0.0564 - val_accuracy: 0.9800 - val_precision: 0.9618 - val_recall: 1.0000\n",
      "Epoch 14/100\n",
      "169/194 [=========================>....] - ETA: 0s - loss: 0.0351 - accuracy: 0.9895 - precision: 0.9794 - recall: 1.0000\n",
      "Epoch 14: val_accuracy improved from 0.98117 to 0.98192, saving model to best_model.h5\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 0.0354 - accuracy: 0.9897 - precision: 0.9797 - recall: 1.0000 - val_loss: 0.0537 - val_accuracy: 0.9819 - val_precision: 0.9652 - val_recall: 1.0000\n",
      "Epoch 15/100\n",
      "169/194 [=========================>....] - ETA: 0s - loss: 0.0325 - accuracy: 0.9906 - precision: 0.9813 - recall: 1.0000\n",
      "Epoch 15: val_accuracy improved from 0.98192 to 0.98267, saving model to best_model.h5\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 0.0319 - accuracy: 0.9908 - precision: 0.9819 - recall: 1.0000 - val_loss: 0.0522 - val_accuracy: 0.9827 - val_precision: 0.9666 - val_recall: 1.0000\n",
      "Epoch 16/100\n",
      "167/194 [========================>.....] - ETA: 0s - loss: 0.0288 - accuracy: 0.9916 - precision: 0.9834 - recall: 1.0000\n",
      "Epoch 16: val_accuracy did not improve from 0.98267\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 0.0295 - accuracy: 0.9918 - precision: 0.9838 - recall: 1.0000 - val_loss: 0.0598 - val_accuracy: 0.9789 - val_precision: 0.9597 - val_recall: 1.0000\n",
      "Epoch 17/100\n",
      "193/194 [============================>.] - ETA: 0s - loss: 0.0267 - accuracy: 0.9924 - precision: 0.9850 - recall: 1.0000\n",
      "Epoch 17: val_accuracy improved from 0.98267 to 0.98380, saving model to best_model.h5\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 0.0267 - accuracy: 0.9924 - precision: 0.9850 - recall: 1.0000 - val_loss: 0.0477 - val_accuracy: 0.9838 - val_precision: 0.9688 - val_recall: 1.0000\n",
      "Epoch 18/100\n",
      "159/194 [=======================>......] - ETA: 0s - loss: 0.0242 - accuracy: 0.9935 - precision: 0.9873 - recall: 1.0000\n",
      "Epoch 18: val_accuracy did not improve from 0.98380\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 0.0243 - accuracy: 0.9934 - precision: 0.9869 - recall: 1.0000 - val_loss: 0.0462 - val_accuracy: 0.9834 - val_precision: 0.9680 - val_recall: 1.0000\n",
      "Epoch 19/100\n",
      "173/194 [=========================>....] - ETA: 0s - loss: 0.0221 - accuracy: 0.9939 - precision: 0.9879 - recall: 1.0000\n",
      "Epoch 19: val_accuracy improved from 0.98380 to 0.99247, saving model to best_model.h5\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 0.0223 - accuracy: 0.9934 - precision: 0.9869 - recall: 1.0000 - val_loss: 0.0408 - val_accuracy: 0.9925 - val_precision: 0.9852 - val_recall: 1.0000\n",
      "Epoch 20/100\n",
      "181/194 [==========================>...] - ETA: 0s - loss: 0.0208 - accuracy: 0.9946 - precision: 0.9894 - recall: 1.0000\n",
      "Epoch 20: val_accuracy did not improve from 0.99247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194/194 [==============================] - 0s 2ms/step - loss: 0.0208 - accuracy: 0.9944 - precision: 0.9888 - recall: 1.0000 - val_loss: 0.0374 - val_accuracy: 0.9913 - val_precision: 0.9830 - val_recall: 1.0000\n",
      "Epoch 21/100\n",
      "168/194 [========================>.....] - ETA: 0s - loss: 0.0185 - accuracy: 0.9952 - precision: 0.9903 - recall: 1.0000\n",
      "Epoch 21: val_accuracy did not improve from 0.99247\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 0.0187 - accuracy: 0.9948 - precision: 0.9898 - recall: 1.0000 - val_loss: 0.0364 - val_accuracy: 0.9887 - val_precision: 0.9780 - val_recall: 1.0000\n",
      "Epoch 22/100\n",
      "185/194 [===========================>..] - ETA: 0s - loss: 0.0157 - accuracy: 0.9961 - precision: 0.9923 - recall: 1.0000\n",
      "Epoch 22: val_accuracy did not improve from 0.99247\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 0.0155 - accuracy: 0.9963 - precision: 0.9926 - recall: 1.0000 - val_loss: 0.0403 - val_accuracy: 0.9853 - val_precision: 0.9716 - val_recall: 1.0000\n",
      "Epoch 23/100\n",
      "171/194 [=========================>....] - ETA: 0s - loss: 0.0149 - accuracy: 0.9960 - precision: 0.9920 - recall: 1.0000\n",
      "Epoch 23: val_accuracy did not improve from 0.99247\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 0.0149 - accuracy: 0.9960 - precision: 0.9920 - recall: 1.0000 - val_loss: 0.0353 - val_accuracy: 0.9887 - val_precision: 0.9780 - val_recall: 1.0000\n",
      "Epoch 24/100\n",
      "191/194 [============================>.] - ETA: 0s - loss: 0.0134 - accuracy: 0.9969 - precision: 0.9938 - recall: 1.0000\n",
      "Epoch 24: val_accuracy did not improve from 0.99247\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 0.0134 - accuracy: 0.9969 - precision: 0.9939 - recall: 1.0000 - val_loss: 0.0327 - val_accuracy: 0.9902 - val_precision: 0.9809 - val_recall: 1.0000\n",
      "Epoch 25/100\n",
      "177/194 [==========================>...] - ETA: 0s - loss: 0.0123 - accuracy: 0.9972 - precision: 0.9943 - recall: 1.0000\n",
      "Epoch 25: val_accuracy did not improve from 0.99247\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 0.0119 - accuracy: 0.9974 - precision: 0.9949 - recall: 1.0000 - val_loss: 0.0412 - val_accuracy: 0.9853 - val_precision: 0.9716 - val_recall: 1.0000\n",
      "Epoch 26/100\n",
      "184/194 [===========================>..] - ETA: 0s - loss: 0.0118 - accuracy: 0.9976 - precision: 0.9952 - recall: 1.0000\n",
      "Epoch 26: val_accuracy did not improve from 0.99247\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 0.0117 - accuracy: 0.9977 - precision: 0.9955 - recall: 1.0000 - val_loss: 0.0295 - val_accuracy: 0.9917 - val_precision: 0.9838 - val_recall: 1.0000\n",
      "Epoch 27/100\n",
      "176/194 [==========================>...] - ETA: 0s - loss: 0.0107 - accuracy: 0.9979 - precision: 0.9957 - recall: 1.0000\n",
      "Epoch 27: val_accuracy did not improve from 0.99247\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 0.0111 - accuracy: 0.9977 - precision: 0.9955 - recall: 1.0000 - val_loss: 0.0361 - val_accuracy: 0.9879 - val_precision: 0.9766 - val_recall: 1.0000\n",
      "Epoch 28/100\n",
      "173/194 [=========================>....] - ETA: 0s - loss: 0.0098 - accuracy: 0.9978 - precision: 0.9957 - recall: 1.0000\n",
      "Epoch 28: val_accuracy improved from 0.99247 to 0.99397, saving model to best_model.h5\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 0.0102 - accuracy: 0.9977 - precision: 0.9955 - recall: 1.0000 - val_loss: 0.0262 - val_accuracy: 0.9940 - val_precision: 0.9881 - val_recall: 1.0000\n",
      "Epoch 29/100\n",
      "173/194 [=========================>....] - ETA: 0s - loss: 0.0094 - accuracy: 0.9978 - precision: 0.9957 - recall: 1.0000\n",
      "Epoch 29: val_accuracy did not improve from 0.99397\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 0.0088 - accuracy: 0.9981 - precision: 0.9961 - recall: 1.0000 - val_loss: 0.0347 - val_accuracy: 0.9883 - val_precision: 0.9773 - val_recall: 1.0000\n",
      "Epoch 30/100\n",
      "168/194 [========================>.....] - ETA: 0s - loss: 0.0081 - accuracy: 0.9980 - precision: 0.9959 - recall: 1.0000\n",
      "Epoch 30: val_accuracy did not improve from 0.99397\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 0.0081 - accuracy: 0.9981 - precision: 0.9961 - recall: 1.0000 - val_loss: 0.0281 - val_accuracy: 0.9910 - val_precision: 0.9823 - val_recall: 1.0000\n",
      "Epoch 31/100\n",
      "182/194 [===========================>..] - ETA: 0s - loss: 0.0070 - accuracy: 0.9983 - precision: 0.9966 - recall: 1.0000\n",
      "Epoch 31: val_accuracy did not improve from 0.99397\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 0.9984 - precision: 0.9968 - recall: 1.0000 - val_loss: 0.0309 - val_accuracy: 0.9898 - val_precision: 0.9801 - val_recall: 1.0000\n",
      "Epoch 32/100\n",
      "137/194 [====================>.........] - ETA: 0s - loss: 0.0069 - accuracy: 0.9989 - precision: 0.9977 - recall: 1.0000\n",
      "Epoch 32: val_accuracy did not improve from 0.99397\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 0.0068 - accuracy: 0.9989 - precision: 0.9977 - recall: 1.0000 - val_loss: 0.0276 - val_accuracy: 0.9913 - val_precision: 0.9830 - val_recall: 1.0000\n",
      "Epoch 33/100\n",
      "163/194 [========================>.....] - ETA: 0s - loss: 0.0068 - accuracy: 0.9983 - precision: 0.9966 - recall: 1.0000\n",
      "Epoch 33: val_accuracy did not improve from 0.99397\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 0.9985 - precision: 0.9971 - recall: 1.0000 - val_loss: 0.0255 - val_accuracy: 0.9921 - val_precision: 0.9845 - val_recall: 1.0000\n",
      "Epoch 34/100\n",
      "167/194 [========================>.....] - ETA: 0s - loss: 0.0060 - accuracy: 0.9985 - precision: 0.9970 - recall: 1.0000\n",
      "Epoch 34: val_accuracy did not improve from 0.99397\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 0.0061 - accuracy: 0.9987 - precision: 0.9974 - recall: 1.0000 - val_loss: 0.0232 - val_accuracy: 0.9932 - val_precision: 0.9867 - val_recall: 1.0000\n",
      "Epoch 35/100\n",
      "166/194 [========================>.....] - ETA: 0s - loss: 0.0049 - accuracy: 0.9992 - precision: 0.9985 - recall: 1.0000\n",
      "Epoch 35: val_accuracy did not improve from 0.99397\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 0.0050 - accuracy: 0.9994 - precision: 0.9987 - recall: 1.0000 - val_loss: 0.0217 - val_accuracy: 0.9940 - val_precision: 0.9881 - val_recall: 1.0000\n",
      "Epoch 36/100\n",
      "168/194 [========================>.....] - ETA: 0s - loss: 0.0051 - accuracy: 0.9991 - precision: 0.9981 - recall: 1.0000\n",
      "Epoch 36: val_accuracy did not improve from 0.99397\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 0.0048 - accuracy: 0.9992 - precision: 0.9984 - recall: 1.0000 - val_loss: 0.0260 - val_accuracy: 0.9921 - val_precision: 0.9845 - val_recall: 1.0000\n",
      "Epoch 37/100\n",
      "175/194 [==========================>...] - ETA: 0s - loss: 0.0042 - accuracy: 0.9993 - precision: 0.9986 - recall: 1.0000\n",
      "Epoch 37: val_accuracy improved from 0.99397 to 0.99473, saving model to best_model.h5\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 0.9992 - precision: 0.9984 - recall: 1.0000 - val_loss: 0.0218 - val_accuracy: 0.9947 - val_precision: 0.9896 - val_recall: 1.0000\n",
      "Epoch 38/100\n",
      "187/194 [===========================>..] - ETA: 0s - loss: 0.0040 - accuracy: 0.9995 - precision: 0.9990 - recall: 1.0000\n",
      "Epoch 38: val_accuracy did not improve from 0.99473\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 0.9995 - precision: 0.9990 - recall: 1.0000 - val_loss: 0.0316 - val_accuracy: 0.9906 - val_precision: 0.9816 - val_recall: 1.0000\n",
      "Epoch 39/100\n",
      "175/194 [==========================>...] - ETA: 0s - loss: 0.0036 - accuracy: 0.9995 - precision: 0.9989 - recall: 1.0000\n",
      "Epoch 39: val_accuracy did not improve from 0.99473\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 0.0036 - accuracy: 0.9995 - precision: 0.9990 - recall: 1.0000 - val_loss: 0.0282 - val_accuracy: 0.9913 - val_precision: 0.9830 - val_recall: 1.0000\n",
      "Epoch 40/100\n",
      "174/194 [=========================>....] - ETA: 0s - loss: 0.0049 - accuracy: 0.9991 - precision: 0.9982 - recall: 1.0000 \n",
      "Epoch 40: val_accuracy did not improve from 0.99473\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 0.0045 - accuracy: 0.9992 - precision: 0.9984 - recall: 1.0000 - val_loss: 0.0252 - val_accuracy: 0.9921 - val_precision: 0.9845 - val_recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100\n",
      "175/194 [==========================>...] - ETA: 0s - loss: 0.0039 - accuracy: 0.9993 - precision: 0.9986 - recall: 1.0000\n",
      "Epoch 41: val_accuracy did not improve from 0.99473\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 0.9994 - precision: 0.9987 - recall: 1.0000 - val_loss: 0.0276 - val_accuracy: 0.9917 - val_precision: 0.9838 - val_recall: 1.0000\n",
      "Epoch 42/100\n",
      "176/194 [==========================>...] - ETA: 0s - loss: 0.0029 - accuracy: 0.9995 - precision: 0.9989 - recall: 1.0000\n",
      "Epoch 42: val_accuracy did not improve from 0.99473\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 0.9995 - precision: 0.9990 - recall: 1.0000 - val_loss: 0.0288 - val_accuracy: 0.9921 - val_precision: 0.9845 - val_recall: 1.0000\n",
      "Epoch 43/100\n",
      "163/194 [========================>.....] - ETA: 0s - loss: 0.0026 - accuracy: 0.9998 - precision: 0.9996 - recall: 1.0000 \n",
      "Epoch 43: val_accuracy did not improve from 0.99473\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 0.9997 - precision: 0.9994 - recall: 1.0000 - val_loss: 0.0341 - val_accuracy: 0.9891 - val_precision: 0.9787 - val_recall: 1.0000\n",
      "Epoch 44/100\n",
      "188/194 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9995 - precision: 0.9990 - recall: 1.0000\n",
      "Epoch 44: val_accuracy did not improve from 0.99473\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 0.9995 - precision: 0.9990 - recall: 1.0000 - val_loss: 0.0259 - val_accuracy: 0.9925 - val_precision: 0.9852 - val_recall: 1.0000\n",
      "Epoch 45/100\n",
      "174/194 [=========================>....] - ETA: 0s - loss: 0.0025 - accuracy: 0.9995 - precision: 0.9989 - recall: 1.0000 \n",
      "Epoch 45: val_accuracy did not improve from 0.99473\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 0.9994 - precision: 0.9987 - recall: 1.0000 - val_loss: 0.0204 - val_accuracy: 0.9940 - val_precision: 0.9881 - val_recall: 1.0000\n",
      "Epoch 46/100\n",
      "193/194 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9994 - precision: 0.9987 - recall: 1.0000\n",
      "Epoch 46: val_accuracy did not improve from 0.99473\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 0.9994 - precision: 0.9987 - recall: 1.0000 - val_loss: 0.0211 - val_accuracy: 0.9928 - val_precision: 0.9859 - val_recall: 1.0000\n",
      "Epoch 47/100\n",
      "183/194 [===========================>..] - ETA: 0s - loss: 0.0018 - accuracy: 0.9998 - precision: 0.9997 - recall: 1.0000\n",
      "Epoch 47: val_accuracy did not improve from 0.99473\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 0.9998 - precision: 0.9997 - recall: 1.0000 - val_loss: 0.0246 - val_accuracy: 0.9925 - val_precision: 0.9852 - val_recall: 1.0000\n",
      "Epoch 48/100\n",
      "169/194 [=========================>....] - ETA: 0s - loss: 0.0015 - accuracy: 0.9998 - precision: 0.9996 - recall: 1.0000 \n",
      "Epoch 48: val_accuracy did not improve from 0.99473\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 0.9998 - precision: 0.9997 - recall: 1.0000 - val_loss: 0.0233 - val_accuracy: 0.9932 - val_precision: 0.9867 - val_recall: 1.0000\n",
      "Epoch 49/100\n",
      "169/194 [=========================>....] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 \n",
      "Epoch 49: val_accuracy did not improve from 0.99473\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0364 - val_accuracy: 0.9906 - val_precision: 0.9816 - val_recall: 1.0000\n",
      "Epoch 50/100\n",
      "193/194 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9998 - precision: 0.9997 - recall: 1.0000 \n",
      "Epoch 50: val_accuracy improved from 0.99473 to 0.99548, saving model to best_model.h5\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 0.9998 - precision: 0.9997 - recall: 1.0000 - val_loss: 0.0176 - val_accuracy: 0.9955 - val_precision: 0.9911 - val_recall: 1.0000\n",
      "Epoch 51/100\n",
      "180/194 [==========================>...] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000   \n",
      "Epoch 51: val_accuracy did not improve from 0.99548\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0214 - val_accuracy: 0.9932 - val_precision: 0.9867 - val_recall: 1.0000\n",
      "Epoch 52/100\n",
      "158/194 [=======================>......] - ETA: 0s - loss: 0.0017 - accuracy: 0.9998 - precision: 0.9996 - recall: 1.0000  \n",
      "Epoch 52: val_accuracy did not improve from 0.99548\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 0.9998 - precision: 0.9997 - recall: 1.0000 - val_loss: 0.0240 - val_accuracy: 0.9932 - val_precision: 0.9867 - val_recall: 1.0000\n",
      "Epoch 53/100\n",
      "154/194 [======================>.......] - ETA: 0s - loss: 0.0013 - accuracy: 0.9998 - precision: 0.9996 - recall: 1.0000   \n",
      "Epoch 53: val_accuracy did not improve from 0.99548\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 0.9998 - precision: 0.9997 - recall: 1.0000 - val_loss: 0.0208 - val_accuracy: 0.9936 - val_precision: 0.9874 - val_recall: 1.0000\n",
      "Epoch 54/100\n",
      "180/194 [==========================>...] - ETA: 0s - loss: 0.0010 - accuracy: 0.9998 - precision: 0.9997 - recall: 1.0000   \n",
      "Epoch 54: val_accuracy did not improve from 0.99548\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 0.9998 - precision: 0.9997 - recall: 1.0000 - val_loss: 0.0175 - val_accuracy: 0.9955 - val_precision: 0.9911 - val_recall: 1.0000\n",
      "Epoch 55/100\n",
      "192/194 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000  \n",
      "Epoch 55: val_accuracy did not improve from 0.99548\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0274 - val_accuracy: 0.9932 - val_precision: 0.9867 - val_recall: 1.0000\n",
      "Epoch 56/100\n",
      "171/194 [=========================>....] - ETA: 0s - loss: 0.0011 - accuracy: 0.9998 - precision: 0.9996 - recall: 1.0000 \n",
      "Epoch 56: val_accuracy did not improve from 0.99548\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 0.9998 - precision: 0.9997 - recall: 1.0000 - val_loss: 0.0265 - val_accuracy: 0.9928 - val_precision: 0.9859 - val_recall: 1.0000\n",
      "Epoch 57/100\n",
      "168/194 [========================>.....] - ETA: 0s - loss: 8.7215e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 57: val_accuracy did not improve from 0.99548\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 8.5462e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0242 - val_accuracy: 0.9932 - val_precision: 0.9867 - val_recall: 1.0000\n",
      "Epoch 58/100\n",
      "166/194 [========================>.....] - ETA: 0s - loss: 8.8479e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 58: val_accuracy did not improve from 0.99548\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 8.7516e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0292 - val_accuracy: 0.9917 - val_precision: 0.9838 - val_recall: 1.0000\n",
      "Epoch 59/100\n",
      "171/194 [=========================>....] - ETA: 0s - loss: 8.3120e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 59: val_accuracy did not improve from 0.99548\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 7.8531e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0225 - val_accuracy: 0.9940 - val_precision: 0.9881 - val_recall: 1.0000\n",
      "Epoch 60/100\n",
      "166/194 [========================>.....] - ETA: 0s - loss: 5.4161e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 60: val_accuracy did not improve from 0.99548\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 5.5788e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0216 - val_accuracy: 0.9944 - val_precision: 0.9889 - val_recall: 1.0000\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161/194 [=======================>......] - ETA: 0s - loss: 6.9082e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 61: val_accuracy did not improve from 0.99548\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 6.6992e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0297 - val_accuracy: 0.9925 - val_precision: 0.9852 - val_recall: 1.0000\n",
      "Epoch 62/100\n",
      "189/194 [============================>.] - ETA: 0s - loss: 9.6443e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 62: val_accuracy did not improve from 0.99548\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 9.5516e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0259 - val_accuracy: 0.9928 - val_precision: 0.9859 - val_recall: 1.0000\n",
      "Epoch 63/100\n",
      "153/194 [======================>.......] - ETA: 0s - loss: 6.2521e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 63: val_accuracy did not improve from 0.99548\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 6.0210e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0274 - val_accuracy: 0.9928 - val_precision: 0.9859 - val_recall: 1.0000\n",
      "Epoch 64/100\n",
      "168/194 [========================>.....] - ETA: 0s - loss: 3.1626e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 64: val_accuracy did not improve from 0.99548\n",
      "194/194 [==============================] - 0s 2ms/step - loss: 3.4870e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 0.0175 - val_accuracy: 0.9955 - val_precision: 0.9911 - val_recall: 1.0000\n",
      "Epoch 64: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, Y, validation_data=(val_x, val_y), epochs=100, verbose=1, callbacks=[es, mc] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "750a68ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = load_model('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8733ea31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1.000, Test: 0.987\n",
      "Train: 1.000, Test: 0.308\n",
      "Train: 1.000, Test: 0.533\n"
     ]
    }
   ],
   "source": [
    "train_loss , train_acc, train_prec, train_recall = saved_model.evaluate(X, Y, verbose=0)\n",
    "test_loss , test_acc, test_prec, test_recall = saved_model.evaluate(scaled_test, y_test, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
    "print('Train: %.3f, Test: %.3f' % (train_prec, test_prec))\n",
    "print('Train: %.3f, Test: %.3f' % (train_recall, test_recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9d8daf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6935703d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e76d1efd",
   "metadata": {},
   "source": [
    "# Applying CNN model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b59860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The x_train and y_train are reshape to input to the CNN model\n",
    "\n",
    "X_tr = (scaled_train.values).reshape(8850,89,1,-1)\n",
    "Y_tr = (pd.DataFrame(y_train_res).values).reshape(8850,1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec62661",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(tfl.Conv2D(32, input_shape = (8850, 89,1), kernel_size=(50,89)))\n",
    "# model.add(tfl.Conv2D(64, kernel_size=(5,5), activation='relu'))\n",
    "model.add(tfl.Flatten())\n",
    "model.add((tfl.Dense(64, activation='relu')))\n",
    "model.add(tfl.Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82de6c6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8cfc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_tr,Y_tr,epochs=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c521c32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7535f877",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ad7246",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d67f5aaf",
   "metadata": {},
   "source": [
    "# Applying LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27544a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(8850,89), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "# model.add(LSTM(128))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(LSTM(256))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(LSTM(64))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(8850, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', keras.metrics.Precision(),\n",
    "                                                                     keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc5d4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(scaled_train).reshape((-1,8850,89))\n",
    "Y = np.array(y_train_res).reshape((-1,8850))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f09268",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tst = np.array(scaled_test).reshape((-1,1919,89))\n",
    "Y_tst = np.array(y_test).reshape((-1,1919))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbb40d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4ced7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0842bca5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(X,Y, epochs=50, shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1784cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Performance = model.evaluate(X_tst, Y_tst, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab68036",
   "metadata": {},
   "outputs": [],
   "source": [
    "Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26792345",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
